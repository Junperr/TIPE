{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junperr/TIPE/blob/main/AI/single_Station.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZYplsvFVcQ1"
      },
      "source": [
        "# Importation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1LiC8yB70QV"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "import sqlite3 as sql\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "import shapely.geometry as geo\n",
        "from scipy.interpolate import griddata\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJnmHxhE308n"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/Info/Tipe/sismic1.db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_D7zwDoVlwi"
      },
      "source": [
        "# Parcours des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl8BX6qoHaxF"
      },
      "source": [
        "ci dessous l'on définit nos set de donnée la partie pour entrainer le model et celle pour vérifier que l'on peut généraliser notre model (on verifie sa précision sur des données qu'il n'a jamais vus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFA0gWW274QE"
      },
      "outputs": [],
      "source": [
        "con=sql.connect('/content/drive/MyDrive/Info/Tipe/sismic1.db')\n",
        "table_earth = pd.read_sql(\"\"\"SELECT * FROM seismes order by mag desc\"\"\",con)\n",
        "table_sta = pd.read_sql(\"\"\"SELECT * FROM station \"\"\",con)\n",
        "table_info = pd.read_sql(\"\"\"SELECT * FROM infos \"\"\",con)\n",
        "print('infos :',table_info.head(),'earthquake :',table_earth.head(),\"station :\",table_sta.head(),sep='\\n'+'####'+'\\n')\n",
        "# station_list = pd.read_sql(\"\"\"SELECT PGA,PGV,mean,std,PGA_UD,PGA_EW,PGA_NS FROM infos \"\"\",sql.connect('sismic1.db'))\n",
        "\n",
        "dftrain = pd.read_sql(\"\"\"\n",
        "SELECT st.code,earthquake_id,mag,PGA,PGV,mean,std,PGA_UD,PGA_EW,PGA_NS FROM infos join station as st\n",
        "on st.code = infos.station_code join seismes as se\n",
        "on se.id==infos.earthquake_id\n",
        "Group By earthquake_id\n",
        "Order by mag DESC \"\"\",sql.connect('/content/drive/MyDrive/Info/Tipe/sismic1.db'))\n",
        "print('dftrain',dftrain.head(),sep='\\n')\n",
        "# print(dftrain,dftrain.loc[0], sep='\\n')\n",
        "print(len(dftrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp6PDDnSgK1a"
      },
      "source": [
        "Quelque graphes pour visualiser la distributions des données:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wv6-luKU8Bb"
      },
      "outputs": [],
      "source": [
        "dfstat_seisme = pd.read_sql(\"\"\"\n",
        "SELECT AVG(nbr_record) as nbr_moy_record,count(*) as nbr_earth,mag from (\n",
        "SELECT count(*) as nbr_record,se.id,se.mag FROM infos join  seismes as se\n",
        "on se.id==infos.earthquake_id\n",
        "group by se.id\n",
        "having nbr_record >20\n",
        ")\n",
        "group by mag\n",
        "order by mag desc\"\"\",sql.connect('/content/drive/MyDrive/Info/Tipe/sismic1.db'))\n",
        "#dftrain['nbr_record']\n",
        "ax = dfstat_seisme.plot.scatter(x='mag', y='nbr_moy_record', c='nbr_earth',grid=True,use_index=True,figsize=(15,7),xlabel=\"magnitude\",cmap='winter',colorbar=True)\n",
        "plt.ylabel('nombre moyen de station',fontsize=20)\n",
        "plt.xlabel('magnitude',fontsize=20)\n",
        "plt.title(label = 'distribution des séismes ',fontsize=20)\n",
        "ax.set_xticks([0.5*x for x in range(4,20)])\n",
        "ax.set_xticklabels([0.5*x for x in range(4,17)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOOb23Lm_JMs"
      },
      "outputs": [],
      "source": [
        "dftrain.mag.hist(bins=50).set_xlabel(\"magnitude\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YlwNfBfOhR1"
      },
      "source": [
        "# Data Normalisation and selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXTJOlG8OnZQ"
      },
      "outputs": [],
      "source": [
        "order_sta = pd.read_sql(\"\"\"SELECT Count(*) as nb_seismes,station_code FROM infos\n",
        "                            Group By station_code\n",
        "                            Order By nb_seismes DESC\"\"\",con)\n",
        "station_model = order_sta['station_code'][0] # pour l'instant on effectue un model sur la station ayant enregistré le plus de seismes\n",
        "data_set = pd.read_sql(\"\"\"  SELECT PGA,mag,long,lat,depth FROM infos AS i Join seismes AS s\n",
        "                            On i.earthquake_id = s.id\n",
        "                            Where i.station_code = '{}'\n",
        "                             \"\"\".format(str(station_model)),con)\n",
        "data_set_normed= data_set.copy()\n",
        "for x in data_set.keys():\n",
        "    if x == 'PGA':\n",
        "        way_back = [data_set_normed[x].mean(),data_set_normed[x].std()]\n",
        "    data_set_normed[x] = (data_set[x]-data_set[x].mean())/data_set[x].std()\n",
        "print(data_set,data_set_normed,sep='\\n')\n",
        "\n",
        "data_set_normed = data_set_normed.sample(frac=1).reset_index(drop=True)\n",
        "# shuffle our data_set, drop=True mean we do not keep old index on a new column\n",
        "n=len(data_set_normed)\n",
        "data_train = data_set_normed[:int(0.90*n)]\n",
        "data_eval = data_set_normed[int(0.90*n):]\n",
        "data_eval = data_eval.reset_index(drop=True)\n",
        "result_train = data_train.pop('PGA')\n",
        "result_eval = data_eval.pop('PGA')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0FuiEHHVt3C"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsl5gnd_H1P8"
      },
      "source": [
        "On créer notre model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8t0zSbjHWsC"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(40000, activation=tf.nn.selu,input_shape=[4]),\n",
        "  tf.keras.layers.Dense(5000, activation=tf.nn.selu),\n",
        "  tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfqmMMAdI-Mm"
      },
      "source": [
        "On le compile:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPqlIagSJBLv"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\",\n",
        "              optimizer=tf.keras.optimizers.Adam(0.00001),metrics=['mae','mse'])\n",
        "list_model = ['SGD', 'RMSprop', 'Adam', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id58zxVVmqu_"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML3g70Va3zME"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "history = model.fit(data_train, result_train, epochs=10000,validation_split=0.2, verbose=False, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM3spXCoeiEC"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "for x in hist.keys():\n",
        "    hist[x] = hist[x] * way_back[1]\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1QdeThWexti"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot([history.history['loss'][i] * way_back[1] for i in range (len(history.history['loss']))], label='loss')\n",
        "  plt.plot([history.history['val_loss'][i] * way_back[1] for i in range (len(history.history['val_loss']))], label='val_loss')\n",
        "  #plt.ylim([0, 100])\n",
        "  #plt.xlim([0,50])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [PGA]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCGvH5_DgCzj"
      },
      "outputs": [],
      "source": [
        "# print(data_eval,result_eval,sep='\\n')\n",
        "X = [x for x in range (0,len(data_eval))]\n",
        "# for x in X :\n",
        "#   print(data_eval[x:x+1],result_eval[x:x+1])\n",
        "model_predict_single = np.array([model.predict(data_eval[x:x+1]) for x in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjR_sMsJkAmc"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize=(20,15))\n",
        "print(way_back)\n",
        "for x in X :\n",
        "    ax.plot(x,(result_eval[x] * way_back[1]) + way_back[0],\"b8\",markersize=8)\n",
        "    ax.plot(x, max((model_predict_single[x][0][0]*way_back[1]) + way_back[0],0) ,\"r*\",markersize=10)\n",
        "for i in range (len(X)//2+len(X)%2):\n",
        "    plt.axvline(2*i, ls='-.', color= 'gray')\n",
        "plt.ylabel(\"PGA\",fontsize=40)\n",
        "plt.legend([\"real values\",'predicted values'],fontsize=25,markerscale=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLbu3xbhV8_Q"
      },
      "source": [
        "# Stop there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuS2zvpMtCkO"
      },
      "outputs": [],
      "source": [
        "X1 = [x for x in range (0,len(data_train))]\n",
        "model_predict_single_train = np.array([model.predict(data_train[x:x+1]) for x in X1])\n",
        "fig1,ax1 = plt.subplots(figsize=(20,15))\n",
        "for x in X1 :\n",
        "  ax1.plot(x,(model_predict_single_train[x][0]* way_back[1]) + way_back[0] ,\"k*\",markersize=10)\n",
        "  ax1.plot(x,(result_train[x]* way_back[1])+way_back[0],\"b8\",markersize=10)\n",
        "plt.grid()\n",
        "plt.ylabel(\"PGA\",fontsize=40)\n",
        "plt.legend(['predicted values',\"real values\"],fontsize=25,markerscale=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1xvLkrkaYu7TSX4T4VEE8fItkKQM0WumA",
      "authorship_tag": "ABX9TyPyOzzK+Vbbp9wokoBCh72S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}